<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CS280A Project4 by Xintian Liu</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/javascript" async
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

  <style>
    /* Reduce padding in the section */
    .section {
      padding-top: 20px;  /* Reduced from Bulma's default 3rem (48px) */
      padding-bottom: 20px;
    }
  
    /* Control spacing inside columns */
    .columns {
      margin-bottom: 10px; /* Adjust margin below columns */
    }
  
    /* Adjust figure caption spacing */
    figure {
      margin-top: 10px;    /* Add slight space above the figure */
      margin-bottom: 10px; /* Reduce default space below the figure */
    }
    
    /* Reduce spacing around the container */
    .container {
      padding-left: 10px;
      padding-right: 10px;
    }
  
  </style>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->

      <a class="navbar-item" href="index.html">Project 1</a>
      <a class="navbar-item" href="project2.html">Project 2</a>
      <a class="navbar-item" href="project3.html">Project 3</a>
      <a class="navbar-item" href="project4.html">Project 4</a>

    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <div class="columns is-centered">
        <div class="column has-text-centered is-10">
          <style>
            .figure-centered {
              display: flex;
              justify-content: center; /* Horizontal centering */
              align-items: center;     /* Vertical centering (if needed) */
            }
          </style>
          
          <figure class="figure-centered">
            <img src="./static/images_proj4/title.JPG" alt="Description of the image" style="width: 80%; height: auto;">
          </figure>
          <h1 class="title is-1 publication-title">CS280A Project 4: IMAGE WARPING and MOSAICING</h1>
        
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://bsac.berkeley.edu/people/xintian-liu">Xintian Liu</a></span>
          </div>
          <div class="column has-text-centered">

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-widescreen">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Part A.1: Shoot the Pictures</h2>
        <div class="content has-text-justified">
          <figure>
            <img src="./static/images_proj4/apartmentview.png" alt="Morph sequence GIF" width="100%" />
            <figcaption>Figure : View from my aparment view (Four photos taken)</figcaption>
          </figure>
          <figure>
            <img src="./static/images_proj4/labview.png" alt="Morph sequence GIF" width="100%" />
            <figcaption>Figure : View from my lab space (Two photos taken)</figcaption>
          </figure>


        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-widescreen">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Part A.2: Recover Homographies</h2>
        <div class="content has-text-justified">
          <p>
            Before warping images into alignment, we need to recover the parameters of the transformation between each pair of images. 
            The transformation is a homography: pâ€™=Hp, where H is a 3x3 matrix with 8 degrees of freedom.
          </p>
          <p>
            $$ \begin{bmatrix} wx' \\ wy' \\ w \end{bmatrix} = H \cdot \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} $$
          </p>
          <p>Where \( H \) is:</p>
          <p>

              $$ H = \begin{bmatrix} h_{11} & h_{12} & h_{13} \\ h_{21} & h_{22} & h_{23} \\ h_{31} & h_{32} & 1 \end{bmatrix} $$
          </p>

          <p>
              Given a point \( (x, y) \) in the first image and its corresponding point \( (x', y') \) in the second image, the equation can be rearranged to:
          </p>
          <p>
              $$ h_{11}x + h_{12}y + h_{13} - h_{31}x \cdot x' - h_{32}y \cdot x' = x' $$
              $$ h_{21}x + h_{22}y + h_{23} - h_{31}x \cdot y' - h_{32}y \cdot y' = y' $$
          </p>
          <p>
            To solve for \( H \), <code>computeH</code> constructs a matrix equation \( A \cdot H = b \) 
            and uses least squares method to find the solution that minimizes the sum of the squared residuals, where:
          </p>
          <p>
            $$ A = \begin{bmatrix} x & y & 1 & 0 & 0 & 0 & -x \cdot x' & -y \cdot x' \\ 0 & 0 & 0 & x & y & 1 & -x \cdot y' & -y \cdot y' \end{bmatrix} $$
          </p>
          <p>The vector \( b \) is:</p>
          <p>
            $$ b = \begin{bmatrix} x' \\ y' \end{bmatrix} $$
          </p>


        </div>
      </div>
    </div>
  </div>
</section>


<section class="section"></section>
  <div class="container is-max-widescreen">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Part A.3: Warp the Images</h2>
        <div class="content has-text-justified">
          <p>
          After computing  \( H \) from corresponding points from two images, I warp the second image to the first image with forward warping and fill the unmapped pixels
          using nearest-neighbor interpolation via <code>warpImage_rec(im, H, polygon = True)</code> The details are:
          </p>
          <ol>
            <li><strong>Original Image Corner Detection and Transformation</strong>:

                  The corners of the original image are identified and projected using the homography matrix \( H \).
                  This defines the boundaries(corners) of the warped image. The max and min coordinates of the transformed corners
                  are used to determine the size of the output image.
            </li>

            <li><strong>Forward Mapping and Interpolation</strong>:
              The original image coordinates are transformed using the homography matrix. A mask is created to identify valid (in-bounds) coordinates for mapping.
              The <code>griddata</code> function with the 'nearest' method is used to interpolate pixel values from the original image to the warped image grid, 
              ensuring that unmapped pixels are filled accurately.

            </li>
            <li><strong>Polygon Masking</strong>:
              If a polygon mask is applied, the shifted corners of the warped image are used to define the polygon region.
              The mask ensures that only the valid region (defined by the warped polygon) is preserved in the final image, while other areas are set to zero.
              
            </li>
        </ol>

        <p>
          Two examples of rectified images are shown below:
        </p>
          

          <figure>
            <img src="./static/images_proj4/rectified_calendar.png" alt="Description of the image" width="100%" />
            <figcaption>Figure : Rectified Image: Calendar</figcaption>
          </figure>

          <figure>
            <img src="./static/images_proj4/rectified_board.png" alt="Description of the image" width="100%" />
            <figcaption>Figure : Rectified Image: Board</figcaption>
          </figure>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section"></section>
  <div class="container is-max-widescreen">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Part A.4: Blend the Images into a Mosaic</h2>
        <div class="content has-text-justified">
          <p>
            The goal of this section is to blend two images smoothly by warping the second image into
             the coordinate of the first image and using a distance transform mask for a gradual transition 
             in the overlapping area of first and second images.

          </p>   
          <ol>
            <li><strong>Distance Transform Mask <code>create_distance_transform_mask</code></strong>:

                  This functions computes the ditance of each pixel from the nearest edge, then normalizes the 
                  distance to the range of 0 and 1.
            </li>
            <li><strong>Blend Two Images <code>BlendTwoImages_Distance</code></strong>:

              This functions mainly involves: (1) Warp the second image; (2)Create a binary mask to identify overlap area;
              (3) Distance transform for alpha blending; (4) Combine the first and second images.
        </li>
          <figure>
            <img src="./static/images_proj4/blended_12.png" alt="Blended view1 & view2" width="100%" />
            <figcaption>Figure : Blended apartment view1 and view2 (Unwarped: view1)</figcaption>
          </figure>
          <figure>
            <img src="./static/images_proj4/blended_34.png" alt="Blended view3 & view4" width="100%" />
            <figcaption>Figure : Blended apartment view3 and view4 (Unwarped: view3) </figcaption>
          </figure>
          <figure>
            <img src="./static/images_proj4/blend_1234.jpg" alt="Blended view1234" width="100%" />
            <figcaption>Figure : Blended apartment view1-4 (Unwarped: view1)  </figcaption>
          </figure>

          <figure>
            <img src="./static/images_proj4/blended_lab12.png" alt="Blended lab12" width="100%" />
            <figcaption>Figure : Blended lab1 and lab2 </figcaption>
          </figure>

          <figure>
            <img src="./static/images_proj4/blended_buildingview.png" alt="Blended lab12" width="100%" />
            <figcaption>Figure : Blended Building inside </figcaption>
          </figure>

        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-widescreen">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
       
                <h2 class="title is-3">Part B.1: Detecting Corner Features</h2>
                <div class="content has-text-justified">
                  <p>Note: For implementation of part B, I realize the images with more features are better candidates
                     for mosaic. So I've taken more pictures for image processing in this part.
                  </p>
                  <figure>
                    <img src="./static/images_proj4b/building_1_and_2.png" alt="Building corner detection" width="500%" />
                    <figcaption>Figure: Buildings.</figcaption>
                  </figure>
                  <figure>
                    <img src="./static/images_proj4b/wall_1_and_2.png" alt="Building corner detection" width="500%" />
                    <figcaption>Figure: Walls.</figcaption>
                  </figure>

                  <!-- Subsection 1 -->
                  <h3 class="title is-4"> Harris Interest Point Detector</h3>
                  <p>
                    We start with directing using harris corner detection given in <code>harris.py</code>.
                    In practice, 
                    I find out <code>min_distance=5</code> and <code>edge_discard=20</code> gives resonable
                    number of harris corners in a short time period.
                  </p>
                  <p>
                    Examples of Harris corners detection are shown below.
                  </p>
                  
                  <figure>
                    <img src="./static/images_proj4b/harris_corners_building12.png" alt="Harris corner detection" width="100%" />
                    <figcaption>Figure: Detected corners in the building images.</figcaption>
                  </figure>
        
        
                  <!-- Subsection 2 -->
                  <h3 class="title is-4">Adaptive Non-Maximal Suppression(ANMS)</h3>
                  <p>To minimize redundant feature corner points, I implement ANMS algorithon[1] as outlined in the function
                    <code>apply_ANMS</code>. The array <code>radii</code> is initialized as infinite values to store
                    the mininum suppression radius for each point.
                  </p>
                  The minimum suppresion radius \( r_i \) is given as:
                  <p>
                    $$ r_i = \min_j \, | \mathbf{x}_i - \mathbf{x}_j |, \quad \text{s.t. } f(\mathbf{x}_i) < c_{\text{robust}} f(\mathbf{x}_j), \quad \mathbf{x}_j \in \mathcal{I} $$
                  </p>
                  <p>
                    For each corner point, the function iteratively computes \( r_i \). A point <code>i</code> of considers 
                    another point <code>j</code> only if <code>f[i] < c_robust * f[j]</code>. This ensures the weak points 
                    are suppressed if they are near a strong point. The Eculidean distance between points <code>i</code> and 
                    <code>j</code> is calculated and stored as the suppresion radius if it is smaller than the 
                    current value.
                  </p>
                  <p>Examples of detected Harris corners with ANMS are shown below. In these cases, <code>c_robust = 0.9</code>
                  and the number of selected points is 500.</p>
                  <p>
                    [1]Brown, Matthew, Richard Szeliski, and Simon Winder. 
                    "Multi-image matching using multi-scale oriented patches." 
                    2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05). 
                    Vol. 1. IEEE, 2005.
                  </p>
                  <figure>
                    <img src="./static/images_proj4b/harris_corners_building12_ANMS.png" alt="Corner detection ANMS" width="100%" />
                    <figcaption>Figure: Detected corners with ANMS.</figcaption>
                  </figure>
        
                </div>
              </div>
            </div>
          </div>
        </section>
      
        

        


        <section class="section">
          <div class="container is-max-widescreen">
            <!-- Abstract -->
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Part B.2: Extracting a Feature Descriptor for Each Feature Point </h2>
                <div class="content has-text-justified">
                  <p>The <code>descriptor</code> function generates descriptors for each selected corners 
                  from the previous parts by extracting the local patches (40x40) around it and downscale it 
                 to 8x8.</p>
                 <p>It is noted that Gaussian blurring is used here to reduce the noise. Then <code>skimage.transform.resize</code> with 
                  <code>anti_aliasing=True</code> is used. To make the descriptor invariant to intensity, the resized patch is normalized.

                 </p>
                  <figure>
                    <img src="./static/images_proj4b/descriptor.png" alt="Descriptor" width="50%" />
                    <figcaption>Figure : A descriptor example.</figcaption>
                  </figure>
                </div>
              </div>
            </div>
          </div>
        </section>

        
        <section class="section">
          <div class="container is-max-widescreen">
            <!-- Abstract -->
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Part B.3: Matching Feature Descriptors between Two Images </h2>
                <div class="content has-text-justified">
                  <p>
                    The <code>feature_matching</code> function identifies corresponding features between two sets 
                    of the descriptors extracted from images by comparing their similarity using Euclidean distance.
                  </p>
                  <p>
                    To ensure reliable matches, the function applies Lowe's ratio test. If the distance to the closest 
                    match is significantly smaller (defined by <code>threshold</code>) than the distance to the second-closest 
                    match, the pair of descriptors is considered as a good match.
                  </p>
                  <p>
                    Output here is a list of matched index pairs representing reliably matched feature points.
                  </p>
                  <figure>
                    <img src="./static/images_proj4b/sample_matched_features.png" alt="Matched features" width="100%" />
                    <figcaption>Figure : View of matched feature descriptors between two images.(Left: Building1, Right: Building2)</figcaption>
                  </figure>
                  <p>
                    However, as shown above, some line pairs indicate incorrect matches that should not be paired. It can be 
                    fixed in next section when finding homography.
                  </p>
       
        
                </div>
              </div>
            </div>
          </div>
        </section>

        <section class="section">
          <div class="container is-max-widescreen">
            <!-- Abstract -->
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Part B.4: A Robust Method (RANSAC) to Compute a Homography </h2>
                <div class="content has-text-justified">
                  <p>
                    From lecture note, RANSAC for estimating homography follows the key steps in RANSAC loop 
                    (<code>num_iteration = 1000</code>): 
                    1. Select four feature pairs (at random); 2. Compute homography \( H \) (exact); 
                    3. Compute \( inliers \) where dist(pi', Hpi) < \( \epsilon \); 4. Keep largest 
                    set of inliers; 5. Re-compute least sqaures H estimate on all of the inliers.
                  </p>
                  <figure>
                    <img src="./static/images_proj4b/inliers.png" alt="Inliers" width="100%" />
                    <figcaption>Figure : Point inliers shown in images.</figcaption>
                  </figure>
                  <p>
                    Now we can see that the incorrect pairs have been removed.
                  </p>
       
        
                </div>
              </div>
            </div>
          </div>
        </section>
        

        <section class="section">
          <div class="container is-max-widescreen">
            <!-- Abstract -->
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Part B.5: Producing Mosaic via Autostitching </h2>
                <div class="content has-text-justified">

                  <figure>
                    <img src="./static/images_proj4b/blend_building.jpg" alt="Inliers" width="100%" />
                    <figcaption>Figure : Blended images of buildings.</figcaption>
                  </figure>
                  <p>
                    More examples:
                    </p>
                    <figure>
                      <img src="./static/images_proj4b/blended_wall.png" alt="Inliers" width="100%" />
                      <figcaption>Figure : Blended images of walls.</figcaption>
                    </figure>

                    <figure>
                      <img src="./static/images_proj4b/blended_lab.png" alt="Inliers" width="100%" />
                      <figcaption>Figure : Blended images of labs.</figcaption>
                    </figure>
       
        
                </div>
              </div>
            </div>
          </div>
        </section>
        
        


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
